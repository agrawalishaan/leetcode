********** GENERAL PATTERNS AND INFO ABOUT THEM **********

kadane's - kadane's is very specifically a 'sliding window' technique where we iterate over an iterable and maintain a dp. If the dp doesn't meet some condition, we reset it in a way, effectively "moving" what would be our left pointer. Kadane's movement follows an inchworm, because when we don't meet a condition we reset the dp to some defined place. It's often easier to update the dp with the current index value immedaitely, then do computations with that, similar to how prefix sums usually include the current number as part of the prefix.

sliding window variable - these are more flexible, in that that the left pointer moves over by some other amount, depending on the problem. For instance finding the minimum size subarray that equals a certain sum (problem 209) consider [1, 3, 5] and our target is at least 6, once we hit [1,3,5] we keep decrementing from the left until we cannot any more. in sliding window we keep expanding until a condition is met (subarry has >= k sum) or broken (we have a repeating character), and then we shrink as much as needed (subarray too small) or (repeating character is gone). We could also just decrement from the left one at a time, and not increment the right. Generally sliding window variable problems will end with an r++ inside the main while loop, and inside the while loop we will decrement from the left until  constraint is hit.

sliding window fixed - intialize some data for the starting window, for instance in 219: Contains Duplicate II, we fill out a set, in 1343: Number of Sub-arrays of Size K and Average..., we calculate a DP sum, and in 239: Sliding Wndow Maximum, we create the queue.
Then, to solve it:
For 219, we do increment pointers, update data, update result. We don't need to compute the very first result because we did it in the setup.

In 1334, we update result, increment pointers, update dpsum. Either works.
If you increment immediately you need to check the initial window in the setup. If you increment at the end, you need to update the relevant data such as the dpsum as well. We can't increment at the end but update the dp sum immediately, because then our first window would be wrong as we double count a value.
We may need to take caution if we update the pointers before the data/result, because if we are at the last r position and update the pointer inside the loop, we will go out of bounds, so we may want to iterate while r < arr.length - 1. If we update the result first, then our pointers will still go out of bounds after (causing the data to be corrupt) but this doesn't matter since this was the last time the result would be updated. Sometimes this is annoying though if our data gets updated in a way that throws an error, for instance in 28, where we used a rolling hash, we can't get the charcode for undefined. We could also check the result immediately, then increment, but increment to length-1 so we don't get a corrupt charcode at the end, and then check the result at the end. Or just put a condition inside the while loop in case we are at the end, which may honestly be easier to implement, such as problem 28.
Also, don't be clever with trying to reuse variables when setting up windows. For instance setting up the initial fixed window, then re-using that variable, r, to iterate over the array. It's easier to just use new for loops with let i=0 and set up the windows nicely, as would make intuitive sense (i.e., iterate over the needle in problem 28 to compute the hash, then iterate over the haystack for the needles length to compute the initial window, then create l and r variables at the right spots)

two pointers - initialize two pointers that will be used to track or update things. Often, these are initialized at the left and right of the iterable, and move inwards, but this is not always the case, for instance: 26. Remove Duplicates from Sorted Array, initializes two pointers at the beginning, one to read and one to update. Two pointers is distinct from sliding window because we aren't considering all the values in the window, rather just the pointers. It is also different from binary since that is a more specific subset of two pointers. In general, two pointer problems will have have a forced increment at the beginning, and it is up to us to determine what to increment and when inside the loop. This is not always the case though, such as in the simple code for 283: Move Zeroes, where we start with two pointers from the beginning.

prefix / postfixes - similar to kadane's, but the difference is we aren't resetting our prefix, we're just establishing cumulative prefixes and postfixes. Prefixes usually include the current number in the prefix, but they don't always have to for instance 238: Product of Array Except Self. Also 435: Non-overlapping intervals, our prefix represents the furthest end time of the prior intervals, but we use that to assess if we need to merge the new interval or not.

a common motif with prefixes or dps or something (think trapping rainwater II my failed attempt at trying to get the row and column constraints when I first tried the Min(rowConstraint, colConstraint) strategy) is:
1- we know some information such as the max heights, this might happen immediately when we enter the loop because they are initialized before the loop starts
2- we use those max heights or that information to compute something
3- we update the new max
but also if our prefix should include the current cell, we might have a pattern like:
1- we dont yet know the information / we might have default values such as infinity or negative infinity
2- we reach a new cell and update the prefix or information based on that cell
3- we process something with that info such as the min length of the subarray

binary search - create two pointers, l and r. Create a middle pointer, I used to initialize it to be the actual value immediately, in case we never enter the while loop, but I couldn't actually find where this was needed. Say we use the floor so it errs left. Our loop will be while (l < r), because once l===r, we only have one possible number left. Immediately upon entering our loop, recalculate m. Since we err left by default, it means our middle value will always be on the left side. If our middle value is the target value, we would need to look left as well, since we chose to err left. For instance [1, 2] and m is pointing at 1, which is our target. We need to search the left side of the array when our target === nums[m], so keep this in mind when changing the way the l and r are set. To know how to set l and r, just think that the binary search is eliminating numbers. Consider [1, 2, 3] with l, m, and r set accordingly. If our middle pointer is too big, or equal to the target, we need to search left. But since it could equal the target, we should consider m still, so r=m. If our middle pointer is strictly too small, we can search all values on the right of it, so l = m + 1. It's also important to note binary search isn't for finding the middle of things, it's for finding something specific inside a range, for instance a number, or the minimum eating speed koko can use to eat bananas (problem 875). It works because we can assess a value and prune half of the tree.
some misceallenous binary notes on a working and not working strategy, due to the err direction being different from how we handle our pointer changes
// [1, 2, 3, 4, 5, 6]

// l = 0
// r = 4
// m = 2 // pushes left

// if 3 <= our target, we need to search right, so l = m

// if 3 > our target, r = m - 1

// [1, 2]
// l = 0
// r = 1
// m = 0

// // working strat
// if 3 < our target, l = m + 1
// if 3 >= our target, r = m

If we are using the floor, we can never set l=m, because that won't compress a window of 2. We must use a ceiling. If we are using a ceiling, we can never set r=m, as it won't compress, we must use r=m-1. 23: Find First and Last Position of Element in Sorted array showcases using both. It also sometimes may be easier to use 3 cases, nums[m]<target, equals, and greater than, and set the windows accordingly.



********** PROBLEM WRITEUPS **********

WRITEUPS:

18: 4sum.js has a good writeup on using `continue` / while loops
54: Maximum Subarray.js explains why we can reset the left wall of kadane's fully, instead of just doing l++
209: Minimum Size Subarray.js showcases how we decrement from l as much as possible until our constraint fails
907: Sum of Subarray Minimums. There are n^2 subarrays, we can compute all their minimums while still in n^2, because we can do something like the following, where we memoize the minimum value for that subarray. BUT there is a linear method.
for (...) {
  let min = Infinity
  for (...) {
    min = ...
  }
}
76: Minimum Window Substring has a good writeup on managing desirability and undesirability of variable sliding windows
240: Search a 2D Matrix II (in binary) has a good writeup on thinking about pivot points and recognizing that you should use pivots in things with sorted properties
380: Insert Delete GetRandomO(1) and 706: Design Hashmap have good writeups on using hash tables, linear probing, etc.
234: Palindrome Linked List has a good writeup on reversing a portion of a linked list and not severing a connection




********** CLARIFICATION FOR ARRAY PROBLEMS **********

// SLIDING WINDOW / KADANES / PREFIX STUFF
max sum of any subarray (any numbers) - we can use kadane's prefix sums

209: minimum size of subarray of sum >=k (positive numbers) - we can use sliding variable window, decrement from left pointer as much as possible when >=k, since we increment r immediately as well. We can't allow negative numbers since then we aren't sure if incrementing the left pointer of the window would cause our sum to increase.
___
not a LC question: number of subarrays / minimum size subarray for sum=k or sum>=k (positive nums), same as above, we can use a sliding window! once we are greater than or equal to the sum, we keep decrementing and adding to our count as long as we still fit the constraint
___
560: Subarray sum equals k, we need to calcuate # of subarrays that = k (any number). We can't use a sliding window due to negatives, but we can maintain a prefix mapping of prefixes we could chop off at any given point.


152: max product of array (any numbers) - we can use a minPrefix and maxPrefix sum

347: top k frequent elements (any nums) - map out occurences : lists of numbers that had that many occurences, iterate backwards




********** LINKED LISTS **********

Linked Lists:
to iterate over a linked list:
while (head) {
  head = head.next;
}
This works because as long as we have a valid element, then the .next will at worst be null. The problem is after this loop ends, we lose the tail. We can either grab the tail inside the the while loop, or use:
while (head && head.next) {
  head = head.next;
}
now, the loop fails when our next element is null. We need the head to be checked too, in case our head is null to begin with, to short circuit null.next

To merge two lists, we can either:
1) Figure out where the head pointer should start at, either l1 or l2. Say head starts at l1. Then we should increment l1 to begin with. We run a comparison between l1 and l2, and add the appropriate .next for the head. Say we do head.next = l2. Now we increment the l2 pointer. At the exact moment we add something to the head, we are creating a really long linked list yes, since it connects all the way to the back, but as we string through them, the end result will be the merged list.
2) Create a dummy node, and use that as the head instead, now l1 and l2 both start at their appropriate starting locations.
Either way, you will need a tail pointer trailing off of the dummy to know where to append to

When reversing part of a linked list, think about the full set of pointers, for instance:
1->2->3->
we reverse starting from 2, making:
<-2<-3
but 1 still points to 2, so we have:
1->2<-3
   V

Good naming conventions are old, slow, fast, current, etc. and if we need multiple iterations, at the beginning we can do let current = head, do our iteration, then reset current to be head again for the next iteration


********** SORTING **********

counting sort / bucket sort strategy - good for things that are bounded by what can be included, for instance sorting a word of only letters

two sort two arrays based on one of them, for instance sort both position = [10,8,0,5,3], speed = [2,4,1,1,3], based on position
we can create an array of tuples of the position and speed pairs:
const tuples = position.map((val, index) => [val, speed[index]]);
then sort tuples based on the values
tuples.sort((a, b) => a[0] - b[0]);
then split them back up


********** MATH **********

math: to find the distance between two points on a line, we can just do abs(p1 - p2)

to get the last digit of a number, do % 10, to remove the last digit, do floor div by 10
to get the first digit of a number, we can keep floor dividing until the number is less than 10. We could speed up the floor div process by using logs to figure out how many digits are in a number, and then floor dividing by a bigger number based on that

2241: Design an ATM Machine and 2244: Minimum Rounds to Complete All Tasks show how we can use math to simplify operations. In design an ATM machine, we need to withdraw the largest bill repeatedly until it would put us over our withdrawn amount, then repeat. Instead of withdrawing one at a time, comparing our remaining amount, and loop (total time complexity = # of bills in the machine, since we could draw each bill one by one), we can calculate with math exactly how many we could withdraw, and the time complexity becomes bound by the # of bill types.

********** ROLLING HASH **********
Say we want to use base 10 for our numbers and hash all strings into a number between 1-10000. We set a MOD=10000.
To hash 'aj', a=1*10^0, j=10*10^1, which is 1+100, 101
when we drop the a, we drop a 1, leaving us with 100. We then divide by 10 to downshift everything, leaving us with 'j' hashes to, which is right.
We could have weird collisions, consider 'sa', s hashes to 19, a hashes to 1*10^1, which is 10. Our sum is 29. When we drop s, we drop 19, leaving us with 10, and when we divide we get 1, it still works. This works because when we drop s, we drop everything responsible for the ones digit (so our division will work), and we drop any extra factors that could affect the tens digit.
But, what if we have a really long alphabet, say # is a letter, and it's value is 105. Then #a equals 105 + 10, 115. When we drop #, we are still left with 10, so it doesn't matter how long our alphabet is. Because whenever we drop the left letter, we're dropping everything that could be more precise/granular than any digit on the right (the ones digit), as well as any other info that would pollute the result afterwards.
We can adjust the base of our hashing function (the power to which we raise digits). Bigger numbers can provide fewer collisions, for instance in base 10, 'aa' and 'k' both hash to 11. But in base 26, 'aa' hashes to 27, there is no single letter that could hash to it. And since each letter would be responsible for a very specific range (1-26^1, 26-26^2) etc, we actually have a perfect hashing function (but it will stop working once we overflow). For instance if we want to hash the strings '1', '2', ... '9', we can make the first digit a singles digit, the second a tens, and so on. So 129 would hash to 921. There is no other way to get 921, because the only way to get a certain hundreds value is to use a specific third value in the original 129, We cannot add up smaller counts, because 9+90 is less than 100. But because we haven't uniquely hashed anything, we aren't benefited, we don't want a 1:1 mapping, which is why we use mod. We also are uniquely hashing because the number of strings is under the base. If we wanted to hash every letter, 'a', 'b', ..., then if we use base 10, k (which is 11) has a collision with aa, because the single digit j was able to intrude on the start of the second digit, a_ which is 10
We should also use mods that are primes, as they generally give a better distribution.
One problem that can occur is if we overflow, for instance consider we hash something, 'abc', 1*1 + 2*10 + 3*100 = 321. But say 321 overflowed our max int size, and resulted in a 5, and not a 321. We would expect when we drop the a, we drop a 1, and get 320, so that we can divide by 10 without concern, but since we overflowed, we actually get 5-1=4, and 4/10 gives us a floating point and messes things up. If 321 overflowed, but say 310 didn't, we could mod each number first, so 1, 20, and 300 all get modded down. But if the 300 itself will overflow to a 1, we will still end up with floating point division.
Also, we could have this issue: abc = 1 + 20 + 300 = 321, and our mod is 100, so we get 21.
bcd 2 + 30 + 400, after our mod we get 32
we shift bcd to cde, we drop a 2, getting 30, so _cd hashes to 30
then we divide by 10, to shift all the digits, so we get a 3 for 'cd'
then we add e, which is 500, and after the mod we get 3 for 'cde', which is wrong.
The issue that stems is that, because we haven taken the mod of things, each character's individual contribution or "power" is lost, so when we divide the hash by the base, we aren't shifting the "place values" correctly, which leads to the wrong hash value for the new window.
What we should do is subtract the outgoing characters contribution to the hash (which in this case is still 2). Now we have 30.

********** TODOS **********

TODO: is min size subarray sum>=k doable with a mapping, for negative numbers? what about the number of subarrays?
TODO: question on discord where someone gave an alg
recursive linked list
2244: minimum rounds to complete all tasks, use a better solution
is there an algorithm to find the NUMBER of contiguous subarrays that have sum => k, in linear time? I can't think of one, for instance: this is potivies only
do recursion attempt for 206
