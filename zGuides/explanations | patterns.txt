********** PROBLEM WRITEUPS **********

WRITEUPS:

18: 4sum.js has a good writeup on using `continue` / while loops
54: Maximum Subarray.js explains why we can reset the left wall of kadane's fully, instead of just doing l++
209: Minimum Size Subarray.js showcases how we decrement from l as much as possible until our constraint fails
907: Sum of Subarray Minimums. There are n^2 subarrays, we can compute all their minimums while still in n^2, because we can do something like the following, where we memoize the minimum value for that subarray. BUT there is a linear method.
for (...) {
  let min = Infinity
  for (...) {
    min = ...
  }
}
76: Minimum Window Substring has a good writeup on managing desirability and undesirability of variable sliding windows
240: Search a 2D Matrix II (in binary) has a good writeup on thinking about pivot points and recognizing that you should use pivots in things with sorted properties
380: Insert Delete GetRandomO(1) and 706: Design Hashmap have good writeups on using hash tables, linear probing, etc.
234: Palindrome Linked List has a good writeup on reversing a portion of a linked list and not severing a connection





********** ANAGRAMS **********

Problem: 483 / 567
Matching character frequencies, we can use a have and a need counter and increment and decrement when needed.





********** TREES / BST **********
104: Maximum Depth of Binary Tree has good writeups on using different searches in very elegant ways.

In problem 543: Diameter of Binary tree, there are a few ways to solve it.
1) bottom up recursion (n), so go down to the bottom, then use the base case results to form something meaningful, update the result if needed, and return the diameter up one level.
2) top down with no memoization (n^2). Iterate through the tree, for each node, solve it's diameter.
3) top down with caching (n). Iterate through the tree, caching the max depth that node can reach. So at a root:
    5
   / \
  1   3
We solve for 5, meaning we recurse / solve for the depths of its children. When the children reach the base case, they terminate. Since we are no longer recursing down, we finally start to solve for the max depths based on the biggest of the children. We set this in the cache, then bubble back up the result.
Then, we do a dfs through each node, checking the max depths of its children, and updating the result.

This was really poorly designed for a couple reasons though! We're already getting the left and right depths at the nodes, we have basically already written the bottom up recursive function. We may as well just update the result there.

I think we could have done it in one funciton too, instead of filling the cache with one function, then iterating through and updating the result with another. It ends up being more confusing and just a worse version of the bottom up recursion though, I feel.

Problem 530 has a successful bottom up recursion (though inorder traversal solution is even nicer). The idea is for each node we need to know the smallest and largest value in its tree. Instead of trying to run two functions, we just track both within the same function, using a tuple. We recurse down to the bottom, the bubble up results.



Inorder traversal will print out a BST in ascending order. We can use this to find the kth largest element or kth smallest element (problem 230)

Inorder, Preorder, Postorder iterative traversals should be reviewed

To construct a tree from the pre and inorder traversals, assuming values are unique, use recursion. The first element of preorder will determine the root, and the inorder array will determine how many elements go into the left child, and how many into the right.

TODO: delete a node in BST

In a BST, we can figure out the neighbors of a value, by looking at the largest values in the left subtree, and the smallest in the right. For instance:

    15
   /  \
  12  20
   \
   14

  To find the largest number smaller than 15, we look at the max in left subtree. To find smallest number that is larger than 20, we find the smallest number in the right subtree. The result would not be the parent of 10, because that is always smaller than elements in the left subtree. However, if the element doesn't have a left subtree, then the left neighbor would be its parent.

  We could do this by iterating through the tree, tracking the largest smaller and smallest larger numbers, terminating when we finish the tree.

  We can also do other valuable things that require a sorted structure, such as finding the minimum, maximum, and range queries (find all elements between x and y) in log n time (except for the range query, which is log n + k, and requires recursing down the bst and pruning). We can also find the largest number that is smaller than n, by traversing the tree. I think it is useful to just think of it as similar to a sorted list, except insertion and deletion are faster, and we don't have O(1) to the nth biggest number. We can find the nth biggest number in O(log n) if each node contains info for the number of nodes in its subtree, including itself.


To check if a tree contains another subtree, we can serialize them and use string matching. Or we can do a full subtree check on each treenode.

A preorder traversal with null nodes always uniquely serializes a tree. Postorder should as well. Proof: https://cs.stackexchange.com/questions/116655/which-tree-traversal-string-is-unique

Inorder does not:

    0
   /
  0

  and

  0
   \
    0

  Both serialize to null, 0, null, 0, null, when using inorder.

Often in trees, we have some recursive function like trimBST, that returns a trimmed version or some modified version of a tree. We can use this itself as the recursive function, and assign our left and right pointers to be the modified versions too, like in problem 669: Trim a Binary Search Tree.

To see a serialization and deserialization with just preorder traversal, see problem 297: Serialize and Deserialize Binary Tree.

A preorder + postorder (without nulls) traversal does not uniquely serialize.
For instance:  1       and          1
                \                  /
                 2                2

Both have pre: 1, 2 and post: 2, 1 traversals.

in a bst we could find the midpoint element in log n time if we knew the size of the left and right subtrees.


********** AVL TREE **********

A self balancing binary tree works by doing rotations, where we rotate around x and y and rearrange subtrees. Sometimes a more complex rotation is needed as the basic rotation does not balance the tree.







********** TODOS **********

TODO: is min size subarray sum=k doable? what about the number of subarrays? what about number of => k?
TODO: question on discord where someone gave an alg
2244: minimum rounds to complete all tasks, use a better solution
// TODO: find sum of all subarrays also for any array
add explanation for problem w95 substring 26nle
leetcode add solutions for contest problems, and one c++ submission i accidentally sent i need to do, same with trapping rainwater2
delete node in bst by reference not by overwriting value
todo: eventually redo construct binary tree from preorder and postorder traversal
// todo: add assesement questions and contest questions
// update all guides to be simplfiied, readable anew, have example problems that illustrate things, do 1 a day maybe
// learn bit
https://cs.stackexchange.com/questions/10538/bit-what-is-the-intuition-behind-a-binary-indexed-tree-and-how-was-it-thought-a

learn seg tree
learn avl tree
learn sqrt decomp


mini processed:
binary search

processed:
sorting